# Описание репозитория

В данном репозитории хранятся доработки различных архитектур, которые необходимо предоставить в качестве самостоятельного выполнения в блоке DL курса [Start ML](https://karpov.courses/ml-start)

## Autoencoder

Автоэнкодер обучен на датасете MNIST с размерами эмбеддингов не более 128. Эмбеддинги сгенерированы для тысячи объектов из обучающей выборки, обучен `RandomForestClassifier`. <br>
*Требования*: accuarcy более 90% <br>
В результате удалось добиться accuracy на тесте 92.3% <br>

## Cifar10: convolutional neural network for dataset Cifar10

Обучена сверточная нейронная сеть, состоящая из 6 сверточных слоев и 3 полносвязных, с применением `batch normalization` и `max pooling `. <br>
*Требования*: accuracy более 88% <br>
В результате удалось добиться accuracy на тесте 88.9% <br>

## TextCNN

Реализация модели `TextCNN` (Convolutional Neural Network for Text Classification) для обработки текстовых данных. В данной модели используются сверточные слои для извлечения признаков из векторных представлений слов, а затем применяется `max pooling` для объединения признаков. Полученные признаки подаются на полносвязный слой для классификации текста. <br>
*Требования*: accuracy более 87% <br>
В результате удалось добиться accuracy на тесте 87.5% <br>

## MLP: MNIST

Многослойный перцептрон, обученный классифицировать датасет MNIST: 2 полносвязный слоя и функция активации `ReLU` <br>
*Требования*: accuracy более 98% <br>
В результате удалось добиться accuracy на тесте 98.3% <br>


## CNN: MNIST

Сверточная нейронная сеть, классифицирующая датасет MNIST. Задачу нужно было решить, используя только сверточные и полносвязные слои, а также `maxpooling` и функцию активации `ReLU` <br>
*Требования*: accuracy более 99.3% <br>
В результате удалось добиться accuracy на тесте 99.34% <br>

## CNN with skip connection

Данный проект представляет собой реализацию сверточной нейронной сети с пропускными соединениями (`skip connections`) для решения задачи классификации изображений CIFAR10. Модель состоит из нескольких блоков сверточных слоев с применением `Batch Normalization`, `ReLU` активации, `Max Pooling` и `Dropout`. <br>
*Требования*: accuracy более 80% <br>
В результате удалось добиться accuracy на тесте 83.6% <br>

## UNET: OXFORD-PETS
Модель для семантической сегментации датасета OXFORD-PETS. В результате были получены предсказания для нужных объектов. <br>
### Структура модели
Модель UNet состоит из следующих компонентов: <br>
**Энкодер**: <br>
- Состоит из четырех блоков conv_plus_conv, каждый из которых содержит два сверточных слоя с батч-нормализацией и функцией активации ReLU, а также операцию пулинга для уменьшения размерности. <br>

**Бутылочное горлышко (Bottleneck)**: <br>
- Последний блок в энкодере, который содержит сверточные слои для извлечения более абстрактных признаков. <br>

**Декодер**:<br>
- Состоит из четырех блоков up_conv, каждый из которых содержит сверточные слои с батч-нормализацией и функцией активации ReLU, а также операцию интерполяции для увеличения размерности. <br>

**Выходной слой**: <br>
- Сверточный слой с одним каналом для получения финального сегментированного изображения. <br>

*Требования*: accuracy более 88% <br>
В результате удалось добиться accuracy на тесте 89.3%

## Faster RCNN: VOCDetection
Модель обнаружения объектов, основанная на архитектуре `Faster R-CNN` с использованием предобученной модели `MobileNetV3 Large 320 FPN`. <br>
В качетсве метрики для замера качества использовалось `MeanAveragePrecision`.

## RetinaNet: VOCDetection
Используем предварительно обученную модель `RetinaNet` с архитектурой `ResNet50-FPN`. Эта модель была обучена на наборе данных `VOCDetection`, который содержит изображения различных объектов с соответствующими метками классов. <br>
Была произведена замена головы классификации модели на `RetinaNetClassificationHead`: количество классов стало соответствовать количеству классов датасета. <br>
*Требования*: четких требований не требуется, нужно сравнить результаты с `Faster RCNN`. <br>
В результате можно сделать вывод, что `RetinaNet` за меньшее количество эпох (10 эпох) достигает лучшего `mAP`, чем `Faster RCNN` (она справилась с этим за 15 эпох), однако обучение занимает значительно большую часть времени

## RoBERTa model: IMDB dataset
Рассматривается задача получения эмбеддингов текстовых данных с использованием модели `RoBERTa` и последующего обучения небольшой модели `MLP` для классификации текста датасета `IMDB`. <br>
*Требования*: accuracy более 86% <br>
В результате удалось добиться accuracy на тесте 90.4%
