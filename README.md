# Описание репозитория

В данном репозитории хранятся доработки различных архитектур, которые необходимо предоставить в качестве самостоятельного выполнения в блоке DL курса [Start ML](https://karpov.courses/ml-start)

## Autoencoder

Автоэнкодер обучен на датасете MNIST с размерами эмбеддингов не более 128. Эмбеддинги сгенерированы для тысячи объектов из обучающей выборки, обучен `RandomForestClassifier`. <br>
*Требования*: accuarcy более 90% <br>
В результате удалось добиться accuracy на тесте 92.3% <br>

## Cifar10: convolutional neural network for dataset Cifar10

Обучена сверточная нейронная сеть, состоящая из 6 сверточных слоев и 3 полносвязных, с применением `batch normalization` and `max pooling `. <br>
*Требования*: accuracy более 88% <br>
В результате удалось добиться accuracy на тесте 88.9% <br>

## Unet

Усложнена и обучена модель Unet с семинара на датасете OXFORD-PETS. Добавлены 5 блоков вверх и вниз, увеличено количество `base_channels`. <br>
*Требования*: accuracy более 88% <br>
В результате удалось добиться accuracy на тесте 88.5% <br>

## TextCNN

Реализация модели `TextCNN` (Convolutional Neural Network for Text Classification) для обработки текстовых данных. В данной модели используются сверточные слои для извлечения признаков из векторных представлений слов, а затем применяется `max pooling` для объединения признаков. Полученные признаки подаются на полносвязный слой для классификации текста. <br>
*Требования*: accuracy более 87% <br>
В результате удалось добиться accuracy на тесте 87.5% <br>
